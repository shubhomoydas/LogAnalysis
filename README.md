# WeblogChallenge

Project in Scala for analyzing log data from Amazon cloud server.

To compile:

    mvn compile

To build JAR:

    mvn package

To run (make a folder 'output' in order for output files to be generated):

    spark-submit --master local[4] target/WeblogChallenge-0.1.0-jar-with-dependencies.jar <operation> [ip address]
    
The command line options are:

    - operation: [0|1|2|3|4|5|6]
    
        0: generate url / user profile data -- outputs file(s) in 'output' folder
            showing users with longest sessions, etc.
        
        1: generate transition data -- generates transition probability tables for
            all users. Probably not required. But useful for debug.
        
        2: generate transition data and simulate arbitrary user navigation --
            in addition to generating the transition probabilities,
            also simulates navigation. This is also not really required unless debugging.
        
        3: simulate navigation for a client IP (requires ip address) -- Extracts all
            logs for a particular IP and builds transition probability tables. Then
            simulates the user (say) 200 times and reports average session length,
            average number of unique urls, average number of total urls per session.
        
        4: generate time series data for server load -- useful to inspect and understand
            server load charactaristics.
        
        5: generate server load data for regression -- useful only if we have lots of
            data over multiple years. Usefulness is mostly moot at this point for this project.
        
        6: predict load for next minute -- Basically average of last 5 minutes load.
        
    - ip address: client IP -- required only for operation 3 (above).

The predictions by operation 6 match quite well with true values. See: 
<a href="https://github.com/shubhomoydas/WeblogChallenge/blob/master/docs/predicted_server_load.pdf">plot.</a>


Below are output files generated by operation '0':

1. output/session_dur.txt -- Orders the user sessions by their duration.
    Seems like most top IPs are either bots or intermediary servers handling data
    for a large number of clients. One of the top IPs 52.74.219.71 is an Amazon server.
    'whois' on random IPs reveals a predominantly Indian client base.
    The output file format is:
    
        ip,session_id,total_navigations,total_time

2. output/user_duration.txt -- Average times per user. Averaged across multiple sessions
    if more than one session is present for a user.
    File format is:
    
        ip,number_of_sessions,avg_session_duration

3. output/session_unique_url_counts.txt -- number of unique URL visits per session

        ip,session_id,unique_url_count
        
4. output/session_url_count.txt -- total number of URL visits for a session

        ip,session_id,num_url_visits,url
        
5. output/urls.txt -- A summary of URLs across users/sessions

        url_id,url,count_visited,avg_time_from_prev_url_in_session


Below is the output file generated by operation '1':

1. output/transitions.txt -- transition probabilities and times. This depends on the URL ids in file output/urls.txt
    
        from_url_id,to_url_id,probability,time_to_navigate


Operation '4' generates:

1. output/per_sec_counts.txt -- contains server load per second in a particular minute.
        
        time,minute_of_day,load

